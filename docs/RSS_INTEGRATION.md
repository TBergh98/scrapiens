# RSS Feed Integration Guide

## Overview

Scrapiens now supports **RSS feed extraction** as a faster, more reliable alternative to HTML scraping.

## Benefits

- ‚ö° **30-50x Faster**: RSS extraction bypasses Selenium/HTTP overhead
- ‚úÖ **More Reliable**: Standardized XML format vs unpredictable HTML
- üîã **Lower Resource Usage**: No browser automation needed
- üîÑ **Backward Compatible**: Existing sites continue to work unchanged

## Configuration

### Adding RSS to a Site

Edit `input/sites.yaml` and add the `rss_url` field:

```yaml
sites:
  - name: example_rss_site
    url: https://example.com/grants
    rss_url: https://example.com/feed.xml  # RSS feed URL
    js: false
    next_selector: null
    max_pages: 1
    pagination_param: null
```

### Sites Without RSS

For sites without RSS feeds, set `rss_url: null`:

```yaml
  - name: standard_site
    url: https://example.com/grants
    rss_url: null  # No RSS - uses standard extraction
    js: false
    next_selector: null
    max_pages: 1
    pagination_param: null
```

## How It Works

### Automatic Routing

The scraper automatically detects `rss_url` and routes accordingly:

1. **If `rss_url` is configured**: Uses RSS extraction (fast path)
2. **If `rss_url` is null**: Uses existing Selenium/HTTP logic (standard path)

### Fallback Mechanism

If RSS extraction fails (e.g., feed is temporarily unavailable), the scraper automatically falls back to standard HTML extraction.

## Usage Examples

### Example 1: Basic RSS Scraping

```python
from scraper import scrape_sites
from pathlib import Path

sites = [
    {
        'name': 'nature_feed',
        'url': 'https://www.nature.com',
        'rss_url': 'https://www.nature.com/nature.rss',
        'js': False,
        'next_selector': None,
        'max_pages': 1,
        'pagination_param': None
    }
]

results = scrape_sites(sites, output_dir=Path('output'))
```

### Example 2: Mixed Configuration

```python
# Some sites with RSS, some without
sites = [
    {
        'name': 'fast_rss_site',
        'rss_url': 'https://example.com/rss.xml',  # RSS enabled
    },
    {
        'name': 'standard_site',
        'rss_url': None,  # No RSS - standard extraction
    }
]
```

### Example 3: Using RSS Extractor Directly

```python
from scraper import RssExtractor

# Extract links from RSS feed
links = RssExtractor.extract_links_from_rss(
    rss_url='https://example.com/feed.xml',
    base_url='https://example.com'
)

print(f"Found {len(links)} links")
```

## Output Format

RSS extraction returns the **same data structure** as standard extraction:

- Returns: `Set[str]` of absolute URLs
- Compatible with all downstream processors (classifier, deduplicator, etc.)

## Finding RSS Feeds

### Common RSS Feed Locations

- `/feed.xml`
- `/rss.xml`
- `/atom.xml`
- `/feed/`
- `/blog/feed/`

### Detection Tips

1. Check site footer for RSS icons
2. Look for `<link rel="alternate" type="application/rss+xml">` in HTML
3. Try common paths listed above
4. Check site's documentation or API docs

## Testing

### Unit Tests

```bash
python -m pytest tests/test_rss_extractor.py -v
```

### Integration Test

```bash
python examples/example_rss_scraping.py
```

## Performance Comparison

| Method | Speed | Reliability | Resource Usage |
|--------|-------|-------------|----------------|
| **RSS** | ‚ö° Very Fast | ‚úÖ High | üü¢ Low |
| HTTP | üöÄ Fast | ‚úÖ Medium | üü° Medium |
| Selenium | üê¢ Slow | ‚ö†Ô∏è Medium | üî¥ High |

## Troubleshooting

### RSS Feed Not Found

```
ERROR: Failed to parse RSS feed: RSS extraction failed
```

**Solution**: Verify the RSS URL is correct and accessible. Set `rss_url: null` to use standard extraction.

### Empty Results

```
WARNING: No entries found in RSS feed
```

**Solution**: The feed may be empty or malformed. The scraper will automatically fall back to standard extraction.

### Invalid XML

```
WARNING: RSS feed parsing warning: <parsing error>
```

**Solution**: The feed may have XML syntax errors. Check the feed with an RSS validator.

## Migration Guide

### Updating Existing Sites

To enable RSS for an existing site:

1. Find the RSS feed URL for the site
2. Add `rss_url: <feed_url>` to the site's configuration in `input/sites.yaml`
3. Run the scraper - it will automatically use RSS

### Gradual Migration

You can migrate sites one at a time:

- Sites with `rss_url` configured: Use RSS
- Sites with `rss_url: null`: Use standard extraction
- **No changes needed to existing code or downstream processing**

## API Reference

### `RssExtractor.extract_links_from_rss(rss_url, base_url="")`

Extract all links from an RSS feed.

**Parameters:**
- `rss_url` (str): URL of the RSS feed
- `base_url` (str): Base URL for resolving relative links (optional)

**Returns:**
- `Set[str]`: Set of absolute URLs found in the feed

**Raises:**
- `ValueError`: If RSS feed is invalid or unreachable

### `RssExtractor.scrape_site_rss(site_config)`

Scrape a site using its RSS feed configuration.

**Parameters:**
- `site_config` (dict): Site configuration with 'rss_url' and 'url' keys

**Returns:**
- `Set[str]`: Set of extracted URLs

## Best Practices

1. **Always Set rss_url**: Explicitly set to URL or `null` for clarity
2. **Test RSS Feeds**: Verify feeds are valid before adding to production
3. **Monitor Logs**: Check for RSS extraction failures in logs
4. **Fallback Ready**: RSS extraction has automatic fallback to standard scraping
5. **Performance**: Prefer RSS when available for better performance

## Implementation Files

Modified:
- `scraper/sites_reader.py` - Added `rss_url` field support
- `scraper/link_extractor.py` - Added RSS routing logic
- `scraper/__init__.py` - Exported `RssExtractor`
- `requirements.txt` - Added `feedparser` dependency

Created:
- `scraper/rss_extractor.py` - RSS extraction module
- `tests/test_rss_extractor.py` - Unit tests
- `examples/example_rss_scraping.py` - Usage example

## Further Reading

- See [IMPLEMENTATION_SUMMARY.md](IMPLEMENTATION_SUMMARY.md) for technical details
- Check [../README.md](../README.md) for full project documentation

# Scrapiens Configuration File

# File Paths
paths:
  # Base directory (can be overridden by BASE_DIR environment variable)
  base_dir: "."
  # Input directory for YAML configuration files
  input_dir: "input"
  # Output directory for extracted links from scraping
  output_dir: "intermediate_outputs/all_links"
  # Unified links file (after deduplication)
  unified_links_file: "intermediate_outputs/link_unificati.json"
  # Classified links file (output of classify command)
  classified_links_file: "intermediate_outputs/classified_links.json"

# Input Files Configuration (YAML format)
input_files:
  # Sites configuration file (list of websites to scrape with their keywords)
  sites_file: "sites.yaml"
  # Keywords configuration file (email addresses and their keywords of interest)
  keywords_file: "keywords.yaml"

# Selenium Configuration
selenium:
  # Run browser in headless mode
  headless: true
  # Browser to use (currently only 'chrome' supported)
  browser: "chrome"
  # Maximum time to wait for elements (seconds)
  implicit_wait: 3
  # Maximum time to wait for page load (seconds)
  page_load_timeout: 8
  # Save screenshots on pagination errors for debugging
  screenshot_on_error: false
  # Initial wait time after page load (seconds)
  initial_wait: 0
  # Wait time after cookie acceptance (seconds)
  cookie_wait: 0

# Web Scraping Configuration
scraping:
  # Default maximum pages to scrape per site
  max_pages_default: 1
  # Number of scroll iterations for JavaScript sites
  scroll_iterations: 8
  # Number of retry attempts for pagination clicks
  pagination_retries: 1
  # Enable JavaScript-based scrolling for dynamic content
  enable_js_scrolling: true
  # Maximum time to wait for page change after pagination (seconds)
  page_change_timeout: 3
  # Extended wait time for content loading (seconds)
  extended_wait: 1
  # Time between scroll iterations (seconds)
  scroll_delay: 0.2
  # Maximum number of expandable elements to click (tabs, "show more", etc.)
  max_expandable_clicks: 30

# Cookie Banner Configuration
cookies:
  # Text patterns to search for in cookie buttons (case insensitive)
  text_patterns:
    - "accept"
    - "accetta"
    - "accept all"
    - "accetta tutti"
    - "accept cookies"
    - "accetta cookie"
    - "i agree"
    - "agree"
    - "acconsento"
    - "ok"
    - "continue"
    - "continua"
    - "allow"
    - "consenti"
    - "consent"
  # CSS selectors for cookie buttons
  attribute_selectors:
    - 'button[id*="accept"]'
    - 'button[class*="accept"]'
    - 'button[class*="cookie"]'
    - 'button[class*="consent"]'
    - 'a[id*="accept"]'
    - 'a[class*="accept"]'
    - 'a[class*="cookie"]'
    - '[data-testid*="accept"]'
    - '[data-testid*="cookie"]'
    - '[aria-label*="accept"]'
    - '[aria-label*="accetta"]'
    - '[aria-label*="cookie"]'

# Overlay Hiding Configuration
overlays:
  # CSS selectors for overlays to hide
  selectors:
    - ".eui-language-selector-button__language-code"
    - ".eui-toolbar"
    - ".eui-toolbar__left"
    - ".eui-toolbar__right"
    - ".eui-input-group-addon"
    - '[role="dialog"]'
    - ".modal"
    - ".overlay"
    - ".cookie-banner"
    - ".notification"

# RSS Classification Configuration
rss_classification:
  # REGEX-only classification strategy for RSS entries
  # Strategy: Match patterns on RSS TITLE field ONLY (with fallback chain)
  #
  # Title field extraction (in priority order):
  #   1. "title" field (RSS standard)
  #   2. "title_detail" field (feedparser structured)
  #   3. "summary" field (Atom standard)
  #   4. "description" field (RSS extracted fallback)
  #
  # If no valid title found:
  #   - Log WARNING
  #   - Return None → fallback to URL-based classification
  #
  # Pattern matching:
  #   - Applied on extracted title ONLY (lowercase)
  #   - Priority order: single_grant → grant_list → other
  #   - First match wins
  #   - If NO regex match: fallback to URL-based classification
  #
  # Domain rules: DEPRECATED/DISABLED
  # These are kept for backward compatibility but NOT used in new logic.
  # Reason: Domain alone cannot determine if link is a grant (see config comments)
  domain_rules: {}
  
  # REGEX patterns for title-based classification
  # Patterns are standard Python regex with word boundaries (\b)
  # Adapted from URL-based rules to their closest title equivalents
  title_patterns:
    single_grant:
      # Singular/grant-specific terminology (maps: bando|grant|funding|submission|application|fellowship|award|opportunity)
      - '\b(bando|grant|submission|application|fellowship|award|opportunity)\b'
      # Explicit calls for proposals (singular semantics in titles)
      - '\b(call for proposals?)\b'
      # Scholarships/fellowships (Italian/English variants)
      - '\b(borsa di studio|scholarship|fellowship|assegno di ricerca)\b'
    grant_list:
      # Plurals and list/collection indicators (maps: bandi|grants|fundings|calls|opportunities|list of|search|browse|directory)
      - '\b(bandi|grants|fundings|calls|opportunities)\b'
      - '\b(list of|elenco|directory|browse|search|index)\b'
      - '\b(aperte|available|open)\b'
    other:
      # Generic/non-grant pages (maps: about|contatti|contact|news|blog|faq|help|support|privacy|terms|policy|allegati|attachments|annex|appendix|vincitori|winners|servizi|services)
      - '\b(about|chi\s+siamo|contatti?|contact|news|blog|faq|frequently\s+asked\s+questions?|help|support|privacy|terms|policy|allegat[oi]|attachments?|annexe?s?|appendi(?:x|ces)|vincitor[ei]|winners?|servizi(?:o|i)?|services?)\b'
      # Titles that explicitly reference external networks or file types
      - '\b(linkedin)\b'
      - '\b(pdf)\b'

# URL-based Classification Configuration
# REGEX patterns for URL-based classification (standard links, not RSS)
# Strategy: Match patterns on URL path and domain (not title)
# Used as fallback when title-based patterns don't match
url_classification:
  patterns:
    other:
      # Generic pages (about, contact, news, etc.)
      - '\b(about|chi\s+siamo|contatti?|contact|news|blog|faq|frequently\s+asked\s+questions?|help|support|privacy|terms|policy|allegat[oi]|attachments?|annexe?s?|appendi(x|ces)|vincitor[ei]|winners?|servizi[oi]?|services?)\b'
      - '/about(/|$|[?#])'
      - '/contact(/|$|[?#])'
      - '/news(/|$|[?#])'
      - '/blog(/|$|[?#])'
      - '/help(/|$|[?#])'
      - '/allegat[oi](/|$|[?#])'
      - '/(attachment|annex|appendix)(/|$|[?#])'
      - '\.pdf($|[?#])'
      - 'linkedin'
    single_grant:
      # Singular forms and specific details pages
      - '\b(bando|grant|detail|submission|application|fellowship|tender|dettagli)\b'
      - '/details?(/|$|[?#])'
      - '/grant(/[^/]|$|[?#])'
      - '/call(/[^/]|$|[?#])'
      - '/bando(/[^/]|$|[?#])'
      - '/tender-details(/|$|[?#])'
      - '/grant-details(/|$|[?#])'
      - '/dettagli-bando(/|$|[?#])'
      - '(/|[?#])(detail|award|opportunity)(/|[?#]|$)'
    grant_list:
      # Plural forms indicating lists/collections
      - '\b(bandi|grants|fundings|calls|opportunities|list\s+of|search|browse|directory)\b'
      - '/bandi(/|$|[?#])'
      - '/grants?s(/|$|[?#])'
      - '/fundings?s(/|$|[?#])'
      - '/calls(/|$|[?#])'
      - '/search(/|$|[?#])'
      - '/browse(/|$|[?#])'
      - '/directory(/|$|[?#])'
      - '(list|directory|index)\..*$'

# Email Configuration
email:
  # Number of days back to filter grants by deadline (only grants with deadline >= today - deadline_filter_days will be included)
  # Grants with null/missing deadline will always be included
  deadline_filter_days: 30

# OpenAI Configuration
openai:
  # Model to use for link classification
  model: "gpt-4o-mini"
  # Request timeout (seconds)
  timeout: 300
  # Progress indicator interval (seconds)
  progress_interval: 10
  # Classification prompt template
  classification_prompt: |
    Analyze the following list of URLs and classify each one into one of these categories:
    
    1. "single_grant" - URLs that lead to a page containing complete information about a SINGLE research grant/call (look for keywords like "bando", "call", "grant", "funding opportunity")
    2. "grant_list" - URLs that lead to a page containing a LIST of MULTIPLE grants/calls
    3. "other" - URLs that are generic pages (contacts, about us, home page, etc.)
    
    Return your response as a JSON array where each object has:
    - "url": the original URL
    - "category": one of "single_grant", "grant_list", or "other"
    - "reason": a brief explanation of why you classified it this way
    
    URLs to classify:
    {urls}

# Grant Details Extraction Configuration
extractor:
  # Model to use for grant details extraction
  model: "gpt-4o-mini"
  # Selenium page load timeout (seconds)
  timeout: 10
  # Number of parallel workers for extraction
  parallel_workers: 10
  # Maximum retry attempts for API failures
  max_retries: 3
  # Extraction prompt template
  extraction_prompt: |
    Validate if this page contains research grant/call information, then extract structured data.
    
    ## Output Schema
    
    If NOT a grant page (contact, FAQ, navigation, error, etc.):
    ```json
    {"is_grant": false, "invalid_reason": "brief 1-2 sentence description"}
    ```
    
    If IS a grant page (has title, organization, description, requirements/dates/budget):
    ```json
    {
      "is_grant": true,
      "title": "string",
      "organization": "string", 
      "abstract": "string",
      "keywords": "string or null",
      "opening_date": "YYYY-MM-DD or null",
      "deadline": "YYYY-MM-DD or null",
      "funding_amount": "string or null"
    }
    ```
    
    ## Field Extraction Rules
    
    **title**: Grant/call title from HTML
    
    **organization**: Organization offering the grant
    
    **abstract**: Description/summary with length-adaptive handling:
    - ≤500 chars: Copy EXACTLY as appears in HTML (preserve all original wording)
    - >500 chars: Intelligent summary (400-500 chars) removing redundancy while preserving domain-specific keywords and key concepts
    - Purpose: Used for keyword matching - maintain technical terms
    
    **keywords**: Extract ONLY from explicit keyword/tag sections ("keywords", "key terms", "tags", "subject areas", "topics"). Format as comma/semicolon-separated string. Return null if no dedicated keyword section exists.
    
    **Date Fields** (opening_date & deadline):
    - Extract ONLY if EXPLICITLY stated with clear date indicators
    - Format: YYYY-MM-DD
    - Return null if vague ("coming soon", "TBD") or ambiguous
    - Never invent or guess dates
    
    Date keyword indicators:
    | Field | English | Italian | Other |
    |-------|---------|---------|-------|
    | opening_date | "opening", "opens", "from", "starts" | "apertura", "a partire da" | - |
    | deadline | "deadline", "closes on", "closed on", "expired on" | "scadenza", "chiude il", "chiuso il", "scaduto il", "termine", "data limite" | - |
    
    **funding_amount**: Extract funding/budget information (e.g., "€500,000", "up to $1M"). Look for: "importo", "finanziamento", "budget", "funding", "amount". Return null if not found.
    
    ## Critical Rules
    - Return ONLY factual information explicitly present in HTML
    - Use null (not empty string) for missing fields
    - Return valid JSON only - no explanations outside JSON
    
    ---
    
    URL: {url}
    
    HTML Content (truncated to first 15000 chars):
    {html}

# Cache Configuration
cache:
  # Enable caching of extracted grant details
  enabled: true
  # Cache file name (will be saved in output_dir)
  file: "grants_cache.json"

# Logging Configuration
logging:
  # Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
  level: "INFO"
  # Log format
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  # Log to file
  log_to_file: true
  # Log file name
  log_file: "scrapiens.log"
